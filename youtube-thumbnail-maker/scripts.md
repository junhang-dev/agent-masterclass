뭔가 신기하지 않아요? 이 모든 게 현실이라는 게. 무슨 뜻이냐면, 그렇게 생각하지 않으세요? 이 모든 AI 관련 내용과 실리콘밸리 이야기가 현실이라는 게요.
정말 공상 과학 소설 같지 않나요? 또 신기한 건 서서히 발전하는 게 당연하게 느껴진다는 거예요.
AI에 GDP의 1%를 투자한다는 아이디어는 훨씬 더 큰일처럼 느껴졌을 텐데, 지금은 그냥 그런가 보다 하게 되는 것 같아요.
우리는 꽤 빨리 익숙해지는 것 같아요. 하지만 추상적이기도 해요. 그게 무슨 의미일까요?
뉴스에서 어느 회사가 얼마를 투자했다고 발표하는 것만 보게 되죠. 그게 전부예요. 아직까지는 다른 방식으로 체감되지는 않아요.
여기서부터 시작해야 할까요? 흥미로운 논의가 될 것 같아요. 좋아요. 평균적인 사람의 관점에서는 별로 달라진 게 없다는 점이 특이점까지도 계속될 거라는 당신의 의견이 흥미롭네요.
아뇨, 그렇게 생각하지 않아요. 알겠습니다. 제가 다르게 느껴지지 않는다고 말한 것은, 어느 회사가 이해하기 어려운 엄청난 금액의 투자를 발표했다는 거예요.
아무도 그걸 어떻게 해야 할지 모르는 것 같아요.
하지만 AI의 영향은 체감될 거라고 생각해요. AI는 경제 전반으로 확산될 거예요.
이를 뒷받침하는 강력한 경제적 힘이 있을 것이고, 그 영향은 매우 강하게 느껴질 것이라고 생각합니다. 그 영향이 언제쯤 나타날 거라고 예상하시나요?
모델은 경제적 영향에 비해 더 똑똑해 보여요. 네. 지금 모델에 대해 매우 혼란스러운 점 중 하나죠.
평가에서 모델이 그렇게 잘하는 것을 어떻게 설명해야 할까요? 평가를 보면 '꽤 어려운 평가인데'라고 생각하게 되죠. 모델이 정말 잘하고 있어요.
하지만 경제적 영향은 훨씬 뒤처지는 것 같아요. 모델이 한편으로는 놀라운 일들을 해내면서, 다른 한편으로는 특정 상황에서 같은 말을 두 번 반복하는 이유를 이해하기가 매우 어렵습니다.
예를 들어, 바이브 코딩을 사용해서 작업을 한다고 가정해 봅시다.
어떤 곳에 갔는데 버그가 생겼어요. 그래서 모델에게 '이 버그 좀 고쳐줄래?'라고 말하면 모델이 '정말 그러네요. 죄송해요.'라고 말하는 거죠.
제가 버그를 발견해서 고치려고 했더니 또 다른 버그가 생기는 거예요.
그래서 '두 번째 버그가 생겼다'고 말하면, '어떻게 이런 실수를 할 수 있지?'라고 답하죠.
'당신 말이 또 맞아요'라면서 첫 번째 버그를 다시 가져오고, 이 두 버그를 번갈아 가며 보여주는 거예요.
어떻게 이런 일이 가능할까요? 저도 확실히는 모르겠지만, 뭔가 이상한 일이 벌어지고 있다는 것을 시사하는 것 같아요.
저는 두 가지 가능한 설명이 있다고 생각합니다. 좀 더 엉뚱한 설명은 강화 학습 훈련이 모델을 너무 좁고 단편적으로 만들어서 다른 면에서는 인지 능력을 향상시키지만, 기본적인 것조차 제대로 못하게 만드는 것일 수도 있다는 겁니다.
이것 때문일 수도 있지만, 다른 설명도 있습니다. 사람들이 사전 훈련을 할 때, 어떤 데이터로 훈련해야 하는지에 대한 질문에 대한 답은 '모든 데이터'였습니다.
사전 훈련을 할 때는 모든 데이터가 필요하죠.
그래서 이 데이터를 쓸지 저 데이터를 쓸지 고민할 필요가 없었습니다.
하지만 강화 학습 훈련을 할 때는 고민이 필요합니다. '이런 종류의 강화 학습 훈련은 이걸 위해, 저런 종류의 강화 학습 훈련은 저걸 위해'라고 말하죠.
제가 듣기로는 모든 회사에 새로운 강화 학습 환경을 만들어서 훈련에 추가하는 팀이 있다고 합니다.
문제는, 글쎄요, 그게 뭘까요? 자유도가 너무 많아요.
만들 수 있는 강화 학습 환경이 너무나 다양합니다. 한 가지 할 수 있는 일은, 그리고 제 생각에는 무심결에 일어나는 일인데, 사람들이 평가에서 영감을 얻는다는 것입니다.
'모델이 출시될 때 정말 잘 작동하면 좋겠다'고 말하는 거죠.
평가가 좋게 나오길 바라면서요. 이 작업에 도움이 될 만한 강화 학습 훈련은 무엇일까요?' 저는 그런 일이 일어난다고 생각하고, 그것이 현재 벌어지고 있는 많은 일들을 설명해 줄 수 있다고 생각합니다.
만약 이것을 모델의 일반화 능력이 실제로 부족하다는 점과 결합하면, 평가 성능과 실제 현실 세계 성능 간의 괴리, 즉 오늘날 우리가 그 의미조차 제대로 이해하지 못하는 현상을 상당 부분 설명할 수 있습니다.
저는 진정한 보상 해킹은 평가에 너무 집중하는 인간 연구자들이라는 아이디어가 마음에 듭니다.
제가 생각하기에 방금 지적하신 점을 이해하거나 생각해 볼 수 있는 두 가지 방법이 있습니다.
하나는 코딩 대회에서 단순히 초인적인 능력을 갖게 되는 것만으로는 모델이 자동으로 더 세련되어지고 코드베이스를 개선하는 방법에 대해 더 나은 판단력을 발휘하지 못한다는 것입니다. 그렇다면 코딩 대회에서 최고의 성능을 내는지만 테스트하는 것이 아니라 더 다양한 환경을 갖춰야 합니다.
X 또는 Y 또는 Z에 가장 적합한 종류의 애플리케이션을 만들 수 있어야 합니다. 또 다른 방법은 아마도 당신이 암시하는 것일 텐데, "애초에 코딩 대회에서 초인적인 능력을 갖게 되는 것이 왜 더 일반적으로 더 세련된 프로그래머가 되지 못하게 하는가?"라고 말하는 것입니다.
어쩌면 해야 할 일은 환경의 양과 다양성을 계속 쌓아 올리는 것이 아니라, 하나의 환경에서 배우고 다른 환경에서 성능을 향상시킬 수 있는 접근 방식을 알아내는 것일지도 모릅니다.
도움이 될 만한 인간적인 비유가 있습니다. 당신이 언급했으니 경쟁적인 프로그래밍의 경우를 예로 들어 보겠습니다. 두 명의 학생이 있다고 가정해 봅시다.
그중 한 명은 최고의 경쟁적인 프로그래머가 되기로 결심하고 해당 분야를 위해 10,000시간을 연습할 것입니다. 그들은 모든 문제를 풀고, 모든 증명 기술을 암기하고, 모든 알고리즘을 빠르고 정확하게 구현하는 데 매우 능숙할 것입니다.
그렇게 함으로써 그들은 최고 중 하나가 되었습니다. 두 번째 학생은 "오, 경쟁적인 프로그래밍은 멋지다"라고 생각했습니다. 아마도 그들은 훨씬 적은 100시간 동안 연습했고, 그들도 정말 잘 해냈습니다.
나중에 누가 더 나은 경력을 쌓을 것이라고 생각하십니까?
두 번째 학생입니다. 맞습니다. 제 생각에는 기본적으로 그런 일이 일어나고 있습니다. 모델은 첫 번째 학생과 훨씬 더 비슷하지만, 훨씬 더 그렇습니다.
왜냐하면 우리는 모델이 경쟁적인 프로그래밍에 능숙해야 한다고 말하고, 그래서 지금까지의 모든 경쟁적인 프로그래밍 문제를 가져와야 한다고 말하기 때문입니다.
그런 다음 데이터 증강을 통해 더 많은 경쟁적인 프로그래밍 문제를 만들고, 그것을 훈련합니다. 이제 훌륭한 경쟁적인 프로그래머가 탄생했습니다.
이 비유를 통해 더 직관적으로 이해할 수 있습니다. 네, 좋아요. 만약 그렇게 잘 훈련되었다면, 모든 다른 알고리즘과 모든 다른 증명 기술이 바로 손끝에 있을 것입니다.
그리고 이러한 수준의 준비로는 다른 것들로 일반화되지 않을 것이라는 것이 더 직관적입니다.
그렇다면 두 번째 학생이 100시간의 미세 조정을 하기 전에 하는 일에 대한 비유는 무엇일까요?
제 생각에 그들은 '그것'을 가지고 있습니다. '그것' 요인이요. 제가 학부생이었을 때, 저와 함께 공부했던 이런 학생이 있었던 게 기억납니다. 그래서 저는 그게 존재한다는 걸 알아요.
저는 '그것'을 사전 훈련이 하는 것과 구별하는 것이 흥미롭다고 생각합니다.
사전 훈련에서 데이터를 선택할 필요가 없다는 것에 대해 방금 말씀하신 내용을 이해하는 한 가지 방법은 그것이 실제로 10,000시간의 연습과 다르지 않다고 말하는 것입니다.
사전 훈련 배포에 이미 어딘가에 있기 때문에 10,000시간의 연습을 무료로 얻을 수 있습니다.
하지만 어쩌면 사전 훈련으로부터 일반화가 그다지 많지 않다고 제안하시는 걸 수도 있겠네요.
사전 훈련에는 데이터가 너무 많지만, 반드시 RL보다 더 잘 일반화되는 것은 아닙니다.
사전 훈련의 주요 강점은 A, 그 양이 매우 많고, B, 사전 훈련에 어떤 데이터를 넣을지 열심히 생각할 필요가 없다는 것입니다.
매우 자연스러운 데이터이고, 사람들이 하는 일, 사람들의 생각, 그리고 많은 특징들을 포함하고 있습니다.
사람들이 텍스트에 투영한 전 세계와 같고, 사전 훈련은 엄청난 양의 데이터를 사용하여 그것을 포착하려고 합니다. 모델이 사전 훈련 데이터에 의존하는 방식을 이해하기가 매우 어렵기 때문에 사전 훈련에 대해 추론하기가 매우 어렵습니다.
모델이 실수를 할 때마다, 우연히 사전 훈련 데이터에 의해 충분히 뒷받침되지 않기 때문일 수 있을까요? '사전 훈련에 의한 지원'은 아마도 느슨한 용어일 것입니다.
이것에 대해 더 유용한 것을 추가할 수 있을지 모르겠습니다. 사전 훈련에 대한 인간적인 비유는 없다고 생각합니다.
다음은 사람들이 사전 훈련에 대한 인간적인 비유로 제안한 비유입니다. 왜 그들이 잠재적으로 틀렸는지에 대한 당신의 생각을 듣고 싶습니다.
하나는 사람이 경제적으로 생산적이지 않지만, 세상을 더 잘 이해하게 만드는 무언가를 하고 있는 18세, 15세 또는 13세까지의 삶에 대해 생각하는 것입니다.
다른 하나는 30억 년 동안 일종의 탐색을 수행하여 인간의 수명 인스턴스를 생성하는 진화에 대해 생각하는 것입니다.
이 둘 중 하나가 사전 훈련과 유사하다고 생각하는지 궁금합니다.
만약 사전 훈련이 아니라면 평생 인간 학습이 어떤 것과 같을지 어떻게 생각하시겠어요? 제 생각에는 이 둘과 사전 훈련 사이에는 몇 가지 유사점이 있고, 사전 훈련은 이 둘의 역할을 모두 수행하려고 합니다.
하지만 큰 차이점도 있다고 생각합니다. 사전 훈련 데이터의 양이 매우 엄청납니다.
네. 어떻게든 인간은 사전 훈련 데이터의 아주 작은 부분으로 15년이 지나도 훨씬 덜 알게 됩니다.
하지만 그들이 아는 것은 어떻게든 훨씬 더 깊이 알고 있습니다. 이미 그 나이에도 우리 AI가 저지르는 실수를 저지르지 않을 것입니다.
또 다른 것이 있습니다. 진화와 같은 것일 수도 있다고 말할 수도 있습니다. 답은 아마도 그렇습니다. 하지만 이 경우에는 진화가 실제로 우위를 점할 수도 있다고 생각합니다.
이 사례에 대해 읽은 기억이 납니다. 신경과학자들이 뇌에 대해 배우는 한 가지 방법은 뇌의 다른 부분에 손상을 입은 사람들을 연구하는 것입니다.
어떤 사람들은 상상할 수 있는 가장 이상한 증상을 가지고 있습니다. 실제로 정말 흥미롭습니다. 관련 있는 한 가지 사례가 떠오릅니다.
뇌 손상, 뇌졸중 또는 사고로 인해 감정 처리가 제거된 사람에 대해 읽었습니다. 그래서 그는 어떤 감정도 느끼지 못하게 되었습니다.
그는 여전히 매우 명료했고 작은 퍼즐을 풀 수 있었고 테스트에서 그는 괜찮아 보였습니다. 하지만 그는 어떤 감정도 느끼지 못했습니다. 그는 슬픔도, 분노도, 활기도 느끼지 못했습니다.
그는 어떻게든 어떤 결정도 내리는 데 매우 서툴게 되었습니다.
어떤 양말을 신을지 결정하는 데 몇 시간이 걸릴 것입니다. 그는 매우 나쁜 재정적 결정을 내릴 것입니다.
본질적으로 우리를 실행 가능한 에이전트로 만드는 데 내장된 감정의 역할에 대해 무엇을 말해 줄까요? 사전 훈련에 대한 질문과 연결하자면, 사전 훈련에서 모든 것을 얻는 데 능숙하다면 그것도 얻을 수 있을 것입니다.
하지만 그것은 마치...
음, 사전 훈련에서 그것을 얻는 것이 가능할 수도 있고 아닐 수도 있습니다. "그것"은 무엇입니까? 분명히 감정만은 아닙니다. 어떤 결정에 대한 최종 보상이 무엇이어야 하는지 알려주는 가치 함수와 같은 것입니다.
사전 훈련에서 암묵적으로 나오지 않는다고 생각하십니까?
그럴 수도 있다고 생각합니다. 그냥 100% 명확하지 않다고 말하는 것입니다.
그런데 그게 뭘까요? 감정에 대해 어떻게 생각하세요? 감정에 대한 머신러닝 비유는 무엇일까요? 일종의 가치 함수 같은 것일 텐데요. 하지만 훌륭한 머신러닝 비유는 없는 것 같아요. 왜냐하면 지금은 가치 함수가 사람들이 하는 일에서 두드러진 역할을 하지 않기 때문입니다.
가치 함수가 무엇인지 청취자들을 위해 정의하는 것이 좋을 것 같습니다. 물론, 저는 그렇게 하는 것이 매우 기쁩니다. 사람들이 강화 학습을 할 때, 지금 강화 학습이 수행되는 방식은, 사람들이 어떻게 에이전트를 훈련시키나요?
신경망이 있고, 신경망에 문제를 제시한 다음, 모델에게 "가서 풀어봐."라고 말합니다. 모델은 아마 수천, 수십만 번의 행동이나 생각 등을 하고, 그런 다음 해결책을 제시합니다.
해결책은 평가됩니다.
그리고 그 점수는 궤적의 모든 단일 행동에 대한 훈련 신호를 제공하는 데 사용됩니다. 즉, 오랫동안 진행되는 작업을 수행하는 경우, 해결하는 데 오랜 시간이 걸리는 작업을 훈련하는 경우, 제안된 해결책을 제시할 때까지 전혀 학습이 이루어지지 않습니다.
이것이 강화 학습이 순진하게 수행되는 방식입니다. 이것이 표면적으로 RL이 수행되는 방식입니다.
가치 함수는 "항상 그런 것은 아니지만, 때로는 당신이 잘하고 있는지 잘못하고 있는지 말해줄 수 있을 거야."와 같이 말합니다. 가치 함수의 개념은 일부 영역에서 다른 영역보다 더 유용합니다.
예를 들어, 체스를 두다가 말을 잃으면 망한 거죠. 제가 방금 한 행동이 나빴다는 것을 알기 위해 게임 전체를 할 필요는 없으며, 따라서 그 이전에 있었던 모든 것도 나빴습니다.
가치 함수를 사용하면 맨 끝까지 기다릴 필요가 없습니다.
수학이나 프로그래밍 같은 것을 하고 있고, 특정 해결책이나 방향을 탐색하려고 한다고 가정해 보겠습니다.
예를 들어, 천 단계의 사고 후에, 이 방향이 유망하지 않다고 결론 내렸습니다.
이것을 결론 내리자마자, 이 경로를 따라가기로 결정했을 때 이미 천 타임스텝 이전에 보상 신호를 얻을 수 있었습니다.
제안된 해결책을 실제로 제시하기 훨씬 전에 "다음에는 비슷한 상황에서 이 경로를 따라가지 말아야겠다."라고 말하는 것입니다.
이것은 DeepSeek R1 논문에 있었는데, 궤적 공간이 너무 넓어서 중간 궤적과 가치 사이의 매핑을 배우기가 어려울 수 있다는 내용이었습니다.
그리고 코딩에서도 마찬가지로 잘못된 아이디어를 가지고 되돌아가서 무언가를 바꾸잖아요.
이건 딥러닝에 대한 믿음이 부족한 것처럼 들리네요. 물론 어려울 수도 있지만 딥러닝으로 못 할 것은 없잖아요.
제 생각에는 가치 함수가 유용할 것이고, 앞으로도 사용될 것이라고 확신합니다. 이미 사용되고 있을 수도 있고요. 감정의 중심이 손상된 사람에 대해 언급한 것은, 인간의 가치 함수가 진화에 의해 하드코딩된 어떤 중요한 방식으로 감정에 의해 조절된다는 것을 시사하는 것일 수도 있다는 것입니다.
어쩌면 그것이 사람들이 세상에서 효과적으로 활동하는 데 중요할 수도 있습니다. 그 점에 대해 질문하고 싶었습니다.
가치 함수의 감정에 대한 정말 흥미로운 점은 이해하기는 비교적 간단하면서도 매우 유용하다는 것입니다.
두 가지 답변이 있습니다. 우리가 배우고 이야기하는 것, 우리가 이야기하는 종류의 AI와 비교했을 때 감정은 비교적 단순하다는 데 동의합니다.
감정이 너무 단순해서 인간이 이해할 수 있는 방식으로 매핑할 수도 있을 겁니다. 그렇게 하면 멋질 것 같아요. 유용성 측면에서 보면 복잡성과 견고성 사이의 균형이 있습니다. 복잡한 것은 매우 유용할 수 있지만, 단순한 것은 매우 광범위한 상황에서 유용합니다.
우리가 보고 있는 것을 해석하는 한 가지 방법은, 우리의 감정이 대부분 포유류 조상으로부터 진화했고, 우리가 사람이었을 때 약간 다듬어졌다는 것입니다.
포유류에게는 없을 수도 있는 사회적 감정을 어느 정도 가지고 있지만, 그다지 정교하지는 않습니다.
정교하지 않기 때문에 우리가 살고 있는 세상과는 매우 다른 세상에서 우리에게 큰 도움이 됩니다. 사실 실수를 하기도 합니다.
예를 들어, 우리의 감정... 배고픔이 감정으로 간주될까요? 논쟁의 여지가 있지만, 예를 들어 배고픔에 대한 우리의 직관적인 느낌은 풍요로운 음식으로 가득한 이 세상에서 우리를 올바르게 인도하는 데 성공하지 못하고 있습니다.
사람들은 데이터 스케일링, 파라미터 스케일링, 컴퓨팅 스케일링에 대해 이야기해 왔습니다.
스케일링에 대해 더 일반적인 방식으로 생각할 수 있을까요? 다른 스케일링 축은 무엇일까요? 여기 제가 생각하기에 사실일 수도 있는 관점이 있습니다.
ML이 과거에 작동했던 방식은 사람들이 그저 이것저것 만지작거리면서 흥미로운 결과를 얻으려고 노력하는 것이었습니다. 과거에는 그런 일이 계속 일어났습니다. 그러다가 스케일링에 대한 통찰력이 나타났습니다.
스케일링 법칙, GPT-3, 그리고 갑자기 모든 사람들이 스케일링을 해야 한다는 것을 깨달았습니다. 이것은 언어가 사고에 어떻게 영향을 미치는지 보여주는 예입니다. '스케일링'은 단지 하나의 단어일 뿐이지만, 사람들에게 무엇을 해야 할지 알려주기 때문에 매우 강력한 단어입니다.
그들은 '스케일링을 해보자'라고 말합니다. 그래서 무엇을 스케일링할 것인지 묻습니다.
사전 훈련은 스케일링할 대상이었습니다. 그것은 특정한 스케일링 레시피였습니다. 사전 훈련의 큰 돌파구는 이 레시피가 좋다는 것을 깨달은 것입니다.
'컴퓨팅과 데이터를 특정 크기의 신경망에 섞으면 결과가 나올 것이다'라고 말합니다.
레시피를 확장하면 더 나아질 것이라는 것을 알게 될 것입니다. 이것 또한 훌륭합니다.
기업들은 이것을 좋아합니다. 왜냐하면 자원을 투자하는 매우 낮은 위험의 방법을 제공하기 때문입니다.
연구에 자원을 투자하는 것은 훨씬 더 어렵습니다. 비교해 보세요. 연구를 한다면 '연구자들은 가서 연구하고 결과를 내놓으라'라고 해야 하지만, 더 많은 데이터를 얻고 더 많은 컴퓨팅을 얻어야 합니다.
사전 훈련에서 무언가를 얻을 수 있다는 것을 알고 있습니다. 실제로 트위터에서 일부 사람들이 말하는 다양한 내용을 바탕으로 볼 때, 제미니가 사전 훈련에서 더 많은 것을 얻을 수 있는 방법을 찾은 것 같습니다.
하지만 언젠가는 사전 훈련에 사용할 데이터가 고갈될 것입니다.
데이터는 매우 명확하게 유한합니다. 다음에 무엇을 해야 할까요? 이전에 했던 것과는 다른 종류의 강화된 사전 훈련을 하거나, RL을 하거나, 아니면 다른 것을 할 수도 있습니다.
하지만 이제 컴퓨팅이 커졌고, 컴퓨팅은 이제 매우 커졌기 때문에, 어떤 의미에서는 우리는 연구의 시대로 돌아왔습니다. 다른 방식으로 표현해 보겠습니다.
2020년까지, 2012년부터 2020년까지는 연구의 시대였습니다. 이제 2020년부터 2025년까지는 스케일링의 시대였습니다. 아마 플러스마이너스, 저 연도에 오차 범위를 더해 보겠습니다. 왜냐하면 사람들은 '이것은 놀랍다.
더 확장해야 한다'라고 말하기 때문입니다.
"계속 확장하는 겁니다." 한 단어로 말하면 확장이죠. 하지만 이제 규모가 너무 커졌습니다.
"규모가 너무 크니까 100배 더 크게 하면 모든 것이 완전히 달라질 것이다"라는 믿음이 정말 있을까요? 분명히 달라지긴 하겠죠.
하지만 규모를 100배로 늘리면 모든 것이 변모할 것이라는 믿음이 있을까요? 저는 그렇지 않다고 생각합니다. 결국 대형 컴퓨터를 사용하는 연구 시대로 돌아가는 것이죠.
매우 흥미로운 표현이네요. 하지만 방금 제시하신 질문을 다시 드려보겠습니다.
무엇을 확장하고 있으며, 레시피를 갖는다는 것은 무엇을 의미할까요? 사전 훈련에서 존재했던 물리학 법칙과 같은 깔끔한 관계를 저는 잘 모르겠습니다.
데이터나 컴퓨팅, 매개변수와 손실 간에 거듭제곱 법칙이 있었습니다. 어떤 종류의 관계를 추구해야 하며, 이 새로운 레시피가 어떻게 보일지 어떻게 생각해야 할까요?
우리는 이미 사전 훈련에서 RL로, 한 유형의 확장(scaling)에서 다른 유형의 확장으로 전환되는 것을 목격했습니다.
이제 사람들은 RL을 확장하고 있습니다. 트위터에서 사람들이 말하는 것을 보면, RL은 상당한 양의 컴퓨팅을 소비할 수 있기 때문에 사전 훈련보다 RL에 더 많은 컴퓨팅을 소비한다고 합니다.
매우 긴 롤아웃을 수행하므로 이러한 롤아웃을 생성하는 데 많은 컴퓨팅이 필요합니다. 그런 다음 롤아웃당 비교적 적은 양의 학습을 얻으므로 실제로 많은 컴퓨팅을 소비할 수 있습니다.
저는 그걸 확장이라고 부르지도 않겠습니다. 저는 그냥 "무엇을 하고 있나요?
지금 하고 있는 일이 가장 생산적인 일인가요? 컴퓨팅을 더 생산적으로 사용하는 방법을 찾을 수 있나요?" 가치 함수에 대한 논의는 앞서 나눴습니다.
사람들이 가치 함수를 잘 다루게 되면 리소스를 더 생산적으로 사용할 수 있을 것입니다.
모델을 훈련하는 완전히 다른 방법을 찾으면 "이것이 확장인가, 아니면 그냥 리소스를 사용하는 것인가?"라고 말할 수 있습니다. 약간 모호해지는 것 같습니다.
사람들이 연구 시대에 있었을 때 "이것도 해보고 저것도 해보자.
저것도 해보고 그것도 해보자. 어, 흥미로운 일이 벌어지고 있네"라고 했던 것처럼 말이죠. 저는 그러한 시대로 다시 돌아갈 것이라고 생각합니다.
연구 시대로 돌아간다면, 한 걸음 물러서서 우리가 가장 중요하게 생각해야 할 레시피의 부분은 무엇일까요?
가치 함수라고 말씀하실 때, 사람들은 이미 현재의 레시피를 시도하고 있지만, LLM을 판사처럼 활용하는 등 여러 가지 방법을 시도하고 있습니다.
그것을 가치 함수라고 할 수도 있지만, 훨씬 더 근본적인 것을 염두에 두고 계신 것 같습니다.
사전 훈련을 완전히 재고하고, 그 과정의 끝에 단계를 더 추가하는 것만이 능사가 아닐까요?
가치 함수에 대한 논의는 흥미로웠다고 생각합니다. 가치 함수는 강화 학습을 더 효율적으로 만들 것이고, 그것이 변화를 가져올 것이라고 강조하고 싶습니다.
하지만 가치 함수로 할 수 있는 모든 것은 가치 함수 없이도 할 수 있지만, 더 느릴 뿐이라고 생각합니다. 제가 생각하기에 가장 근본적인 것은 이러한 모델들이 사람보다 훨씬 더 나쁜 일반화를 보인다는 것입니다.
정말 명백합니다. 그것은 매우 근본적인 것 같습니다. 핵심은 일반화입니다. 여기에는 두 가지 하위 질문이 있습니다.
하나는 샘플 효율성에 관한 것입니다. 왜 이러한 모델이 인간보다 학습하는 데 훨씬 더 많은 데이터가 필요할까요?
두 번째 질문은 데이터의 양과는 별개로, 왜 모델에게 우리가 원하는 것을 가르치는 것이 인간에게 가르치는 것보다 그렇게 어려울까요?
인간에게는 검증 가능한 보상이 반드시 필요하지 않습니다... 아마 지금 여러 연구원들을 멘토링하고 있을 텐데, 그들과 대화하고, 코드를 보여주고, 당신이 생각하는 방식을 보여주고 있을 겁니다.
그것으로부터 그들은 당신의 사고방식과 연구 방법을 배우고 있습니다.
"좋아, 이것이 커리큘럼의 다음 부분이고, 이제 이것이 당신 커리큘럼의 다음 부분이야. 오, 이 훈련은 불안정했어."와 같은 검증 가능한 보상을 설정할 필요가 없습니다. 이러한 번거롭고 특별한 과정이 없습니다.
아마도 이 두 가지 문제가 어떤 식으로든 관련이 있을 수 있지만, 저는 지속적인 학습과 같은 두 번째 문제와 샘플 효율성과 같은 첫 번째 문제를 탐구하는 데 관심이 있습니다.
인간의 샘플 효율성에 대한 가능한 설명 중 하나는 진화라는 점을 궁금해할 수도 있습니다.
진화는 우리에게 가능한 가장 유용한 정보의 작은 양을 제공했습니다. 시각, 청각, 운동과 같은 것들에 대해서는 진화가 우리에게 많은 것을 주었다는 강력한 주장이 있다고 생각합니다.
예를 들어, 인간의 손재주는 훨씬 뛰어넘습니다... 제 말은 로봇도 시뮬레이션에서 엄청난 양의 훈련을 받으면 손재주가 좋아질 수 있습니다.
하지만 로봇이 실제 세계에서 사람처럼 새로운 기술을 빠르게 익히도록 훈련하는 것은 매우 요원해 보입니다. 여기서 "아, 그래, 이동 말이야.
우리 조상들은 모두 훌륭한 이동 능력이 필요했지, 다람쥐처럼. 그러니 이동 능력에 있어서는 아마 우리가 상상할 수 없는 선험적 지식을 가지고 있을 거야." 시각에 대해서도 같은 주장을 할 수 있습니다.
얀 르쿤은 아이들이 10시간의 연습 후에 운전을 배운다고 지적했는데, 이는 사실입니다.
하지만 우리의 시각은 매우 좋습니다. 적어도 저는 5살 때를 기억합니다. 그때 저는 자동차에 매우 열광했습니다.
제가 5살 때 이미 자동차 인식 능력이 운전에 충분했을 거라고 확신합니다.
5살 때는 데이터를 많이 접할 수 없습니다. 대부분의 시간을 부모님 집에서 보내기 때문에 데이터 다양성이 매우 낮습니다.
하지만 그것도 진화 때문이라고 말할 수 있겠죠. 하지만 언어, 수학, 코딩은 아마 아닐 겁니다.
여전히 모델보다 나아 보입니다. 분명히 모델은 언어, 수학, 코딩에서 평균적인 인간보다 낫습니다. 하지만 학습 능력에서는 평균적인 인간보다 나을까요?
아, 그렇죠. 아, 물론이죠. 제가 말하려던 것은 언어, 수학, 코딩, 특히 수학과 코딩은 사람들을 학습에 능하게 만드는 것이 복잡한 선험적 지식이라기보다는 그 이상의 어떤 것, 근본적인 것이라는 점을 시사한다는 것입니다.
잘 이해가 안 됩니다. 왜 그래야 하죠?
사람들이 일종의 뛰어난 신뢰성을 보이는 기술을 생각해 보세요. 그 기술이 수백만 년, 수억 년 동안 우리 조상에게 매우 유용했던 것이라면, 아마 인간이 진화 때문에, 즉 우리가 가지고 있는 선험적 지식, 진화론적 선험적 지식이 매우 모호한 방식으로 인코딩되어 있어서 우리를 그렇게 잘하게 만드는 것일 수 있다고 주장할 수 있습니다.
하지만 사람들이 최근에야 존재하게 된 영역에서 뛰어난 능력, 신뢰성, 견고성, 학습 능력을 보인다면, 이는 사람들이 단순히 더 나은 머신 러닝을 가지고 있을 가능성이 더 크다는 것을 나타냅니다.
그렇다면 그걸 어떻게 생각해야 할까요? ML에 빗대어 말하면 무엇일까요? 몇 가지 흥미로운 점이 있습니다. 샘플이 더 적게 필요하고, 더 비지도적입니다.
아이들이 차를 운전하는 법을 배우는 것과 같습니다. 십 대가 차를 운전하는 법을 배울 때, 미리 만들어진 검증 가능한 보상을 받는 것은 아닙니다.
기계 및 환경과의 상호 작용에서 비롯됩니다. 샘플이 훨씬 적게 필요하고, 더 비지도적이며, 더 강력한 것 같습니다.
훨씬 더 강력합니다. 사람들의 견고함은 정말 놀랍습니다. 이 모든 일이 동시에 일어나는 이유에 대해 통일된 사고방식을 가지고 있습니까?
이와 같은 것을 실현할 수 있는 ML 비유는 무엇일까요? 십 대 운전자가 외부 교사 없이 자신의 경험으로부터 스스로 교정하고 배울 수 있는 방법에 대해 질문하신 적이 있습니다.
그 답은 그들이 가치 함수를 가지고 있다는 것입니다. 그들은 또한 사람들에게 매우 강력한 일반적인 감각을 가지고 있습니다.
인간의 가치 함수가 무엇이든, 중독과 관련된 몇 가지 예외를 제외하고는 실제로 매우 강력합니다. 운전을 배우는 십 대의 경우, 운전을 시작하면 즉시 자신의 운전 실력, 얼마나 못하는지, 얼마나 자신감이 없는지 알 수 있습니다.
그리고 나서 '좋아'라고 생각합니다. 그리고 물론 십 대의 학습 속도는 매우 빠릅니다.
10시간 후면 운전할 수 있습니다.
인간은 어떤 해결책을 가지고 있는 것 같지만, 저는 그들이 어떻게 하고 있는지, 왜 그렇게 어려운지 궁금합니다. 이와 같은 것을 가능하게 하려면 모델을 훈련하는 방식을 어떻게 재구상해야 할까요?
정말 좋은 질문입니다. 그리고 저는 그 질문에 대해 많은 의견을 가지고 있습니다.
하지만 불행히도 우리는 모든 머신 러닝 아이디어가 자유롭게 논의되지 않는 세상에 살고 있으며, 이것도 그중 하나입니다. 아마도 그렇게 할 수 있는 방법이 있을 것입니다.
저는 가능하다고 생각합니다. 사람들이 그렇다는 사실은 가능할 수 있다는 증거라고 생각합니다. 하지만 또 다른 장애물이 있을 수 있습니다. 인간의 뉴런이 우리가 생각하는 것보다 더 많은 연산을 수행할 가능성이 있다는 것입니다.
만약 그것이 사실이고, 그것이 중요한 역할을 한다면, 상황은 더 어려워질 수 있습니다.
하지만 어쨌든, 저는 제가 의견을 가지고 있는 몇 가지 머신 러닝 원칙의 존재를 지적한다고 생각합니다. 하지만 불행히도 상황이 자세히 논의하기 어렵게 만듭니다.
이 팟캐스트는 아무도 안 듣고 있어요, 일리야. 궁금하네요. 연구 시대로 돌아간다고 말씀하셨는데, 2012년부터 2020년까지 그곳에 계셨잖아요.
연구 시대로 돌아간다면 분위기가 어떻게 될까요? 예를 들어, AlexNet 이후에도 실험을 실행하는 데 사용되는 컴퓨팅 양은 계속 증가했고, 프론티어 시스템의 크기도 계속 증가했습니다.
이제 이 연구 시대에도 엄청난 양의 컴퓨팅이 필요할 것이라고 생각하시나요?
과거 자료를 다시 찾아보고 오래된 논문을 읽어야 할 것이라고 생각하시나요? Google과 OpenAI, Stanford 등 연구 분위기가 더 강했던 곳에 계셨잖아요?
커뮤니티에서 어떤 종류의 것들을 기대해야 할까요? 스케일링 시대의 한 가지 결과는 스케일링이 방안의 모든 공기를 빨아들였다는 것입니다.
스케일링이 방안의 모든 공기를 빨아들였기 때문에 모두가 똑같은 일을 하기 시작했습니다. 우리는 아이디어보다 회사가 훨씬 더 많은 세상에 도달했습니다.
사실 그것에 대해 실리콘 밸리에는 아이디어는 싸고 실행이 전부라는 말이 있습니다.
사람들은 그 말을 많이 하고, 그 말에는 진실이 있습니다. 하지만 트위터에서 누군가가 "아이디어가 그렇게 싸다면 왜 아무도 아이디어를 내지 못하는 걸까요?"라고 말하는 것을 봤습니다. 그리고 그것도 사실이라고 생각합니다.
연구 진행 상황을 병목 현상 측면에서 생각하면 몇 가지 병목 현상이 있습니다. 그중 하나는 아이디어이고, 다른 하나는 아이디어를 실현하는 능력입니다. 이는 컴퓨팅일 수도 있지만 엔지니어링일 수도 있습니다.
90년대로 돌아가서, 예를 들어, 꽤 좋은 아이디어를 가진 사람들이 있었고, 더 큰 컴퓨터가 있었다면 자신의 아이디어가 실현 가능하다는 것을 증명할 수 있었을 것입니다.
하지만 그럴 수 없었기 때문에 아무도 설득하지 못하는 아주 작은 시연만 할 수 있었습니다.
그래서 병목 현상은 컴퓨팅이었습니다. 스케일링 시대에는 컴퓨팅이 많이 증가했습니다. 물론 얼마나 많은 컴퓨팅이 필요한가라는 질문이 있지만, 컴퓨팅은 큽니다.
컴퓨트 파워가 충분히 커서 어떤 아이디어를 증명하는 데 그만큼 더 많은 컴퓨트 파워가 필요한지 명확하지 않습니다. 비유를 들어보겠습니다.
AlexNet은 두 개의 GPU로 구축되었습니다. 그것이 사용된 총 컴퓨트 양이었습니다. 트랜스포머는 8개에서 64개의 GPU로 구축되었습니다. 단일 트랜스포머 논문 실험에서 2017년의 64개 이상의 GPU를 사용한 적이 없는데, 이는 오늘날의 GPU 2개와 같을 것입니다.
ResNet 말이죠?
01 추론이 세상에서 가장 컴퓨트 집약적인 것은 아니었다고 주장할 수 있습니다. 따라서 연구에는 확실히 어느 정도의 컴퓨트 파워가 필요하지만, 연구를 위해 절대적으로 가장 큰 컴퓨트 파워가 필요한 것은 결코 명확하지 않습니다.
가장 훌륭한 시스템을 구축하려면 훨씬 더 많은 컴퓨트 파워를 갖는 것이 도움이 된다고 주장할 수 있으며, 저는 그것이 사실이라고 생각합니다.
특히 모든 사람이 동일한 패러다임 내에 있는 경우 컴퓨트 파워는 큰 차별화 요소 중 하나가 됩니다.
당신이 실제로 그 자리에 있었기 때문에 역사를 묻는 것입니다. 실제로 무슨 일이 일어났는지 잘 모르겠습니다. 최소한의 컴퓨트 파워를 사용하여 이러한 아이디어를 개발할 수 있었던 것 같습니다.
그러나 트랜스포머는 즉시 유명해지지 않았습니다. 그것은 모든 사람이 시작하고 그 위에 실험하고 구축하기 시작한 것이 되었는데, 그 이유는 더 높은 수준의 컴퓨트 파워에서 검증되었기 때문입니다.
맞습니다.
그리고 SSI에 50개의 다른 아이디어가 있다면, 다른 최첨단 연구소가 보유한 종류의 컴퓨트 파워 없이는 어떤 것이 다음 트랜스포머이고 어떤 것이 깨지기 쉬운지 어떻게 알 수 있습니까?
그 점에 대해 언급할 수 있습니다. 짧게 말하면 SSI를 언급하셨습니다. 특히 우리에게 SSI가 연구를 위해 보유한 컴퓨트 파워의 양은 실제로 그렇게 적지 않습니다.
이유를 설명하고 싶습니다. 간단한 수학으로 우리가 보유한 컴퓨트 파워의 양이 생각보다 연구에 비견될 만한 이유를 설명할 수 있습니다. 설명하겠습니다. SSI는 30억 달러를 모금했는데, 이는 절대적인 의미에서 많은 금액입니다.
하지만 "다른 회사들이 훨씬 더 많은 금액을 모금하는 것을 보세요."라고 말할 수도 있습니다. 하지만 그들의 컴퓨트 파워의 많은 부분이 추론에 사용됩니다.
이 큰 숫자, 이 큰 대출은 추론을 위해 책정됩니다. 그것이 첫 번째입니다.
두 번째로, 추론을 수행하는 제품을 가지려면 많은 엔지니어, 영업사원이 필요합니다. 많은 연구가 모든 종류의 제품 관련 기능을 생산하는 데 전념해야 합니다.
그래서 실제로 연구에 남은 것을 보면 차이가 훨씬 줄어듭니다.
또 다른 점은, 뭔가 다른 것을 하고 있다면, 그것을 증명하기 위해 절대적인 최대 규모가 정말로 필요한가 하는 것입니다.
전혀 그렇지 않다고 생각합니다. 제 생각에는 우리의 경우, 우리가 하고 있는 일이 옳다는 것을 우리 자신과 다른 사람들에게 증명하고 확신시킬 수 있는 충분한 컴퓨팅 능력을 가지고 있습니다.
OpenAI와 같은 회사들이 실험에만 연간 50억에서 60억 달러를 지출한다는 공공연한 추정치가 있습니다.
이것은 추론 등에 지출하는 금액과는 별개입니다. 그래서 그들은 당신들이 총 투자한 금액보다 더 많은 돈을 연간 연구 실험에 쓰고 있는 것 같습니다.
그것은 무엇을 하느냐의 문제라고 생각합니다. 무엇을 하느냐의 문제입니다.
그들의 경우, 다른 사람들의 경우에는 훈련 컴퓨팅에 대한 수요가 훨씬 더 많습니다. 훨씬 더 많은 다양한 작업 흐름이 있고, 다른 양식이 있고, 더 많은 것들이 있습니다.
그래서 파편화됩니다. SSI는 어떻게 돈을 벌 것인가? 이 질문에 대한 저의 대답은 대략 이렇습니다. 지금은 연구에만 집중하고 있으며, 그러면 그 질문에 대한 답이 드러날 것입니다.
가능한 답은 많이 있을 것이라고 생각합니다. SSI의 계획은 여전히 초지능을 향해 직진하는 것입니까?
아마도요. 저는 그것에 장점이 있다고 생각합니다.
일상적인 시장 경쟁에 영향을 받지 않는 것은 매우 좋습니다. 하지만 계획을 변경하게 될 수 있는 두 가지 이유가 있다고 생각합니다.
하나는 실용적인 이유인데, 만약 시간 제약이 길어진다면 그럴 수도 있습니다. 두 번째로, 저는 최고로 강력한 AI가 세상에 나와 영향을 미치는 데 큰 가치가 있다고 생각합니다.
저는 이것이 의미 있게 가치 있는 일이라고 생각합니다. 그렇다면 왜 당신의 기본 계획은 초지능을 향해 직진하는 것입니까?
왜냐하면 OpenAI, Anthropic, 다른 모든 회사들은 명시적으로 '보세요, 우리는 대중이 익숙해지고 대비할 수 있는 점점 더 약한 지능을 가지고 있습니다'라고 생각하는 것처럼 들리기 때문입니다. 초지능을 직접 구축하는 것이 잠재적으로 왜 더 나은가요?
찬반 양론을 모두 이야기해 보겠습니다. 옹호하는 이유는 시장에 있는 사람들이 직면하는 어려움 중 하나는 그들이 치열한 경쟁에 참여해야 한다는 것입니다.
결국 힘든 레이스는 어려운 선택을 강요한다는 점에서 꽤 힘듭니다. "이 모든 것으로부터 우리 자신을 보호하고 연구에만 집중해서 준비가 되었을 때만 나오자."라고 말하는 것은 좋지만, 반론도 타당하며, 그것들은 상반되는 힘입니다.
반론은 "세상이 강력한 AI를 보는 것이 유용하다는 것입니다.
세상이 강력한 AI를 보는 것이 유용한 이유는 그것이 아이디어를 전달할 수 있는 유일한 방법이기 때문입니다." 음, 아이디어를 전달하는 것뿐만 아니라 AI를 전달할 수 있습니다.
AI를 전달한다. "AI를 전달한다"는 게 무슨 뜻인가요?
AI에 대한 에세이를 쓰고 에세이에서 "AI는 이렇게 될 것이고, 저렇게 될 것이고, 이렇게 될 것이다."라고 쓴다고 가정해 봅시다. 당신은 그것을 읽고 "좋아요, 흥미로운 에세이네요."라고 말합니다. 이제 AI가 이것을 하고, 저것을 하는 것을 본다고 가정해 봅시다.
비교할 수 없습니다. 기본적으로 저는 AI가 대중에게 공개되는 것이 큰 이점이 있다고 생각하며, 그것이 우리가 곧장 나아가지 않는 이유가 될 것입니다.
그것뿐만이 아니라, 그것이 중요한 부분이라고 생각합니다.
또 다른 큰 점은, 인간 공학과 연구 분야에서 최종 결과물이 안전하게 만들어지도록 생각하는 것만으로 안전하게 만들어진 사례를 생각해 낼 수 없다는 것입니다. 오늘날 비행기 사고율이 수십 년 전보다 훨씬 낮은 이유와는 대조적입니다.
리눅스에서 버그를 찾는 것이 수십 년 전보다 훨씬 더 어려운 이유는 무엇일까요?
제 생각에는 이러한 시스템이 세상에 배포되었기 때문입니다. 실패를 발견하고, 그 실패를 수정하고, 시스템이 더 강력해졌습니다.
AGI와 초인적인 지능이 왜 다를지 모르겠습니다. 특히, 우리가 곧 다룰 내용이겠지만, 초지능의 해악은 악의적인 페이퍼 클리퍼가 존재하는 것만이 아닌 것 같습니다.
하지만 이것은 정말 강력한 것이고, 우리는 사람들이 그것과 어떻게 상호 작용할지, 사람들이 그것으로 무엇을 할지조차 개념화하는 방법을 모릅니다.
점진적으로 접근하는 것이 그것의 영향을 분산시키고 사람들이 그것에 대비하도록 돕는 더 나은 방법인 것 같습니다.
음, 제 생각에는 이 점에서, 스트레이트 샷 시나리오에서도 점진적인 출시를 해야 할 것 같아요. 그게 제가 상상하는 방식입니다. 점진주의는 어떤 계획에도 내재된 요소가 될 것입니다.
단지 문밖으로 가장 먼저 내보낼 것이 무엇이냐의 문제일 뿐입니다. 그게 첫 번째입니다. 두 번째로, 저는 당신이 다른 사람들보다 지속적인 학습을 옹호해 왔다고 믿고, 실제로 이것이 중요하고 올바른 일이라고 생각합니다.
이유는 다음과 같습니다. 언어가 사고에 어떤 영향을 미치는지에 대한 또 다른 예를 들어보겠습니다.
이 경우에는 모든 사람의 사고를 형성한 두 단어가 될 것입니다.
첫 번째 단어: AGI. 두 번째 단어: 사전 훈련. 설명해 드리겠습니다. AGI라는 용어는 왜 존재할까요?
매우 특정한 용어입니다. 왜 존재할까요? 이유가 있습니다. AGI라는 용어가 존재하는 이유는, 제 생각에는, 지능의 어떤 최종 상태에 대한 매우 중요하고 필수적인 설명이라기보다는, 기존에 존재했던 다른 용어에 대한 반작용이기 때문입니다. 그 용어는 좁은 AI입니다.
게임 플레이와 AI의 고대 역사, 체커 AI, 체스 AI, 컴퓨터 게임 AI로 거슬러 올라가면, 모든 사람들이 이 좁은 지능을 보라고 말할 것입니다.
물론, 체스 AI는 카스파로프를 이길 수 있지만, 다른 것은 아무것도 할 수 없습니다.
너무 좁습니다. 인공 좁은 지능입니다. 그래서 이에 대한 반응으로, 어떤 사람들은 이것은 좋지 않다고 말했습니다. 너무 좁습니다.
우리에게 필요한 것은 일반 AI, 모든 것을 할 수 있는 AI입니다. 그 용어는 많은 인기를 얻었습니다. 두 번째로 많은 인기를 얻은 것은 사전 훈련, 특히 사전 훈련의 레시피입니다.
저는 요즘 사람들이 RL을 하는 방식이 사전 훈련의 개념적 각인을 되돌리는 것일 수도 있다고 생각합니다.
그러나 사전 훈련은 이러한 속성을 가지고 있었습니다. 사전 훈련을 더 많이 할수록 모델은 모든 것을 더 잘하게 됩니다. 대체로 균일하게요. 일반 AI. 사전 훈련은 AGI를 제공합니다. 그러나 AGI와 사전 훈련에서 일어난 일은 어떤 의미에서 목표를 넘어섰다는 것입니다.
특히 사전 훈련의 맥락에서 'AGI'라는 용어에 대해 생각해보면, 인간은 AGI가 아니라는 것을 알게 될 것입니다.
네, 확실히 기술의 기반이 있지만, 인간은 엄청난 양의 지식이 부족합니다.
대신에, 우리는 지속적인 학습에 의존합니다. 그래서 '좋아요, 우리가 성공을 거두고 안전한 초지능을 만들어냈다고 가정해 봅시다.'라고 생각할 때, 문제는 그것을 어떻게 정의하느냐는 것입니다.
지속적인 학습 곡선에서 어디에 위치할까요? 저는 의욕이 넘치는 15세의 초지능을 만들어냅니다.
그들은 아는 것이 거의 없지만, 훌륭한 학생이고 매우 열심입니다.
프로그래머가 되거나 의사가 되거나 가서 배우십시오. 따라서 배포 자체가 일종의 시행착오 학습 기간을 포함할 것이라고 상상할 수 있습니다.
완성된 것을 떨어뜨리는 것이 아니라 과정입니다.
알겠습니다. 초지능으로 지적하시는 것은 경제의 모든 직업을 수행하는 방법을 아는 완성된 정신이 아니라는 것을 암시하시는군요.
예를 들어, 원래 OpenAI 헌장 등이 AGI를 정의하는 방식은 인간이 할 수 있는 모든 직업, 모든 것을 할 수 있다는 것입니다.
대신 모든 직업을 배우는 정신, 즉 초지능을 제안하시는군요.
네. 하지만 일단 학습 알고리즘이 있으면 인간 노동자가 조직에 합류하는 것과 같은 방식으로 세상에 배포됩니다.
정확합니다. 이 두 가지 중 하나가 일어날 것 같습니다. 아마도 둘 다 일어나지 않을 수도 있습니다.
첫째, 이 초효율적인 학습 알고리즘은 인간을 초월하여 ML 연구 과제에서 당신만큼, 잠재적으로는 더 나아집니다.
결과적으로 알고리즘 자체는 점점 더 초인간적이 됩니다. 다른 하나는, 그런 일이 일어나지 않더라도 단일 모델이 있는 경우(이것은 명시적으로 당신의 비전입니다) 경제를 통해 다양한 직업을 수행하고, 그 직업을 수행하는 방법을 배우고, 직장에서 계속 학습하고, 인간이 습득할 수 있는 모든 기술을 습득하지만, 동시에 모든 기술을 습득한 다음 학습 내용을 통합하면 기본적으로 소프트웨어에서 재귀적인 자기 개선 없이도 기능적으로 초지능이 되는 모델을 갖게 됩니다.
이제 경제의 모든 직업을 수행할 수 있는 모델이 있고 인간은 같은 방식으로 정신을 합칠 수 없기 때문입니다.
광범위한 배포로 인해 일종의 지능 폭발을 예상하십니까?
저는 우리가 빠른 경제 성장을 이룰 가능성이 높다고 생각합니다. 광범위한 배포를 통해 상충되는 두 가지 주장을 할 수 있다고 생각합니다.
하나는 일단 어떤 것을 빨리 배우는 AI를 갖게 되고, 그런 AI가 많아지면 경제에 배포하려는 강력한 힘이 생길 것이라는 것입니다. 규제가 막지 않는 한 말이죠. 그런데 규제가 있을 수도 있습니다.
하지만 한동안 매우 빠른 경제 성장이 가능하다는 생각은 광범위한 배포를 통해 매우 가능하다고 생각합니다.
문제는 얼마나 빠를 것인가입니다.
한쪽에는 매우 효율적인 노동자가 있고, 다른 한쪽에는 세상이 정말 크고 많은 것들이 있으며, 그 모든 것들이 다른 속도로 움직이기 때문에 알기가 어렵다고 생각합니다.
하지만 다른 한편으로는 이제 AI가 할 수 있게 되었습니다... 그래서 저는 매우 빠른 경제 성장이 가능하다고 생각합니다. 우리는 규칙이 다른 여러 나라들을 보게 될 것이고, 규칙이 더 친화적인 나라일수록 경제 성장이 더 빠를 것입니다.
예측하기 어렵습니다. 제 생각에는 이것은 매우 불안정한 상황인 것 같습니다.
궁극적으로는 이것이 가능해야 한다는 것을 알고 있습니다. 학습 능력이 인간만큼 뛰어난 존재가 있고, 인간이 융합할 수 없는 방식으로 뇌를 융합할 수 있다면, 이미 이것은 물리적으로 가능해야 할 것 같습니다.
인간도 가능하고, 디지털 컴퓨터도 가능합니다. 이 두 가지를 결합하여 이 존재를 만들어내기만 하면 됩니다.
또한 이런 종류의 존재는 매우 강력할 것 같습니다. 경제 성장은 그것을 표현하는 한 가지 방법입니다. 다이슨 스피어는 엄청난 경제 성장입니다.
하지만 또 다른 방법은 잠재적으로 매우 짧은 시간 안에... SSI에서 사람들을 고용하면 6개월 안에 순 생산성을 낼 수 있을 것입니다.
인간은 정말 빠르게 배우고, 이 존재는 매우 빠르게 더 똑똑해지고 있습니다. 그것이 잘 되도록 하려면 어떻게 해야 할까요? 왜 SSI가 그것을 잘 할 수 있는 위치에 있을까요?
SSI의 계획은 무엇인가요? 기본적으로 제가 물어보고 싶은 것은 그것입니다.
제 생각이 바뀌고 있는 방식 중 하나는 AI가 점진적으로 그리고 사전에 배포되는 것이 더 중요하다는 것입니다. AI에 대해 매우 어려운 점 중 하나는 아직 존재하지 않는 시스템에 대해 이야기하고 있고 그것을 상상하기 어렵다는 것입니다.
제 생각에 일어나고 있는 일 중 하나는 실제로 AGI를 느끼기가 매우 어렵다는 것입니다.
AGI를 느끼기가 매우 어렵습니다. 우리는 그것에 대해 이야기할 수 있지만, 늙고 허약할 때 늙는 것이 어떤 것인지에 대해 대화하는 것을 상상해 보세요.
대화를 나누고 상상하려고 노력할 수 있지만 어렵고, 그렇지 않은 현실로 돌아오게 됩니다.
AGI와 미래의 힘에 대한 많은 문제는 상상하기가 매우 어렵다는 사실에서 비롯된다고 생각합니다.
미래의 AI는 다를 것입니다. 강력해질 것입니다. 실제로 전체 문제, AI와 AGI의 문제는 무엇일까요?
전체 문제는 힘입니다. 전체 문제는 힘입니다. 힘이 정말 커지면 어떻게 될까요?
지난 1년 동안 제가 생각을 바꾼 방식 중 하나는, 그리고 그 생각의 변화는 저희 회사의 계획에 영향을 미칠 수도 있다는 점을 감안하면, 상상하기 어렵다면 어떻게 해야 할까요?
그것을 보여줘야 합니다. 그것을 보여줘야 합니다. AI를 연구하는 대부분의 사람들도 일상에서 보는 것과는 너무 다르기 때문에 상상할 수 없다고 생각합니다.
제가 예측하는 일이 있습니다. 이것은 예측입니다. AI가 더 강력해짐에 따라 사람들은 행동을 바꿀 것이라고 생각합니다.
우리는 지금 일어나고 있지 않은 전례 없는 모든 종류의 일들을 보게 될 것입니다. 몇 가지 예를 들어보겠습니다. 좋든 싫든 프론티어 기업들이 정부와 마찬가지로 앞으로 일어날 일에 매우 중요한 역할을 할 것이라고 생각합니다.
보게 될 것이라고 생각하는 종류의 일들은 치열한 경쟁자들이 AI 안전에 대해 협력하기 시작하는 것입니다.
OpenAI와 Anthropic이 첫 번째 작은 발걸음을 내딛는 것을 보셨을 수도 있지만, 이전에는 존재하지 않았습니다.
그건 제가 3년 전에 했던 강연에서 예측했던 것 중 하나인데, 그런 일이 일어날 거라고요. 저는 또한 AI가 계속해서 더 강력해지고 눈에 띄게 강력해짐에 따라 정부와 대중이 무언가를 하려는 욕구가 생길 것이라고 생각합니다.
AI를 보여주는 것이 매우 중요한 힘이라고 생각합니다.
그게 첫 번째입니다. 두 번째, 좋아요, AI가 구축되고 있습니다.
무엇을 해야 할까요? 제가 계속 주장하는 것 중 하나는 지금 AI를 연구하는 사람들은 AI가 실수 때문에 강력하다고 느끼지 못한다는 것입니다.
저는 언젠가 AI가 실제로 강력하다고 느끼기 시작할 것이라고 생각합니다. 그런 일이 생기면 모든 AI 회사가 안전에 접근하는 방식에 큰 변화가 있을 것이라고 생각합니다.
훨씬 더 편집증적이 될 겁니다. 이런 일이 일어날 것이라는 예측으로 말씀드립니다.
제가 맞는지 지켜보죠. 하지만 AI가 더 강력해지는 것을 보게 될 것이기 때문에 이런 일이 일어날 것이라고 생각합니다.
지금 일어나고 있는 모든 일은 사람들이 오늘날의 AI를 보고 미래의 AI를 상상하기 어렵기 때문이라고 생각합니다.
세 번째로 필요한 일이 있습니다. 회사에 대해 물어보셨기 때문에 SSI의 관점에서만 이야기하는 것이 아니라 더 넓은 의미로 이야기하고 있습니다.
질문은 기업이 무엇을 구축하기를 열망해야 하는가입니다. 무엇을 구축하기를 열망해야 할까요? 모두가 몰두해 온 큰 아이디어가 하나 있는데, 바로 자기 개선 AI입니다.
왜 그랬을까요? 기업보다 아이디어가 적기 때문입니다. 하지만 저는 더 나은 것을 구축할 수 있다고 생각하고, 모든 사람이 그걸 원할 거라고 생각합니다.
그것은 바로 지각 있는 생명체를Robustly 신경 쓰도록 조정된 AI입니다.
특히 AI 자체가 지각이 있기 때문에 인간의 생명만을 신경 쓰는 AI보다 지각 있는 생명체를 신경 쓰는 AI를 구축하는 것이 더 쉬울 것이라는 주장이 있을 수 있다고 생각합니다.
그리고 거울 뉴런이나 동물에 대한 인간의 공감과 같은 것들을 생각해보면, 충분히 크지 않다고 주장할 수도 있지만 존재합니다.
저는 우리가 우리 자신을 모델링하는 데 사용하는 것과 동일한 회로로 다른 사람을 모델링한다는 사실에서 비롯된 창발적 속성이라고 생각합니다. 왜냐하면 그것이 가장 효율적인 방법이기 때문입니다.
그래서 AI가 지각 있는 존재를 신경 쓰게 된다고 해도, 사실 정렬 문제를 해결했을 때 그렇게 해야 하는 건지조차 확실하지 않지만, 대부분의 지각 있는 존재는 AI일 것입니다.
결국 수조, 수십조의 AI가 생겨날 것입니다.
인간은 지각 있는 존재의 아주 작은 부분에 불과할 것입니다. 따라서 목표가 미래 문명에 대한 일종의 인간 통제라면, 이것이 최선의 기준인지도 불분명합니다.
맞습니다. 그것이 최선의 기준이 아닐 수도 있습니다.
두 가지를 말씀드리겠습니다. 첫째, 지각 있는 생명체를 배려하는 것은 가치가 있다고 생각합니다.
고려해야 합니다. 기업들이 이런 상황에 처했을 때 사용할 수 있는 아이디어 목록이 있으면 도움이 될 것 같습니다.
그게 두 번째입니다. 셋째, 가장 강력한 초지능의 힘이 어떤 식으로든 제한된다면 이러한 우려 사항이 많이 해결될 것이기 때문에 실제로 도움이 될 것이라고 생각합니다.
어떻게 해야 할지 확신이 서지 않지만, 정말 강력한 시스템에 대해 이야기할 때는 그것이 실질적으로 도움이 될 것이라고 생각합니다.
정렬에 대한 논의를 계속하기 전에 그 점을 자세히 알아보고 싶습니다. 정상에는 얼마나 많은 여지가 있을까요?
초지능에 대해 어떻게 생각하시나요? 이 학습 효율성 아이디어를 사용하여 새로운 기술이나 지식을 매우 빠르게 학습할 수 있다고 생각하시나요?
더 큰 전략 풀을 가지고 있을 뿐인가요? 더 강력하거나 더 큰 중심에 응집력 있는 '그것'이 있나요?
그렇다면 이것이 나머지 인간 문명에 비해 신과 같은 존재가 될 것이라고 상상하시나요, 아니면 또 다른 에이전트 또는 에이전트 클러스터처럼 느껴지나요?
이것은 사람들이 서로 다른 직관을 가지고 있는 영역입니다. 확실히 매우 강력할 것이라고 생각합니다.
제가 보기에 가장 가능성이 높은 것은 여러 AI가 거의 동시에 생성될 것이라는 것입니다. 클러스터가 충분히 크다면, 예를 들어 클러스터가 말 그대로 대륙 크기라면 정말 강력할 수 있다고 생각합니다.
말 그대로 대륙 크기의 클러스터가 있다면 이러한 AI는 매우 강력할 수 있습니다.
제가 말씀드릴 수 있는 것은, 만약 여러분이 매우 강력한 AI, 정말로 엄청나게 강력한 AI에 대해 이야기하고 있다면, 그들이 어떤 식으로든 제약을 받거나 어떤 합의 같은 것이 있다면 좋을 것이라는 것입니다.
초지능에 대한 우려는 무엇인가요?
그 우려를 설명하는 한 가지 방법은 무엇일까요? 충분히 강력한 시스템, 정말로 충분히 강력한 시스템을 상상해 보세요. 그리고 여러분은 매우 단호한 방식으로 지각 있는 생명체를 돌보는 것과 같이 합리적인 일을 해야 한다고 말할 수 있습니다. 우리는 그 결과를 좋아하지 않을 수도 있습니다.
그게 정말 핵심입니다.
어쩌면, 그런데, 해답은 일반적인 의미에서 RL 에이전트를 구축하지 않는 것일 수도 있습니다.
몇 가지 지적하겠습니다. 저는 인간이 준-RL 에이전트라고 생각합니다.
우리는 보상을 추구하고, 감정이나 다른 것들이 우리를 보상에 싫증나게 하고, 우리는 다른 보상을 추구합니다. 시장은 매우 근시안적인 종류의 에이전트입니다.
진화도 마찬가지입니다. 진화는 어떤 면에서는 매우 지능적이지만, 다른 면에서는 매우 멍청합니다. 정부는 세 부분 간의 끊임없는 싸움이 되도록 설계되었으며, 이는 영향을 미칩니다.
저는 이런 것들을 생각합니다. 이 논의를 어렵게 만드는 또 다른 것은 우리가 존재하지 않는 시스템, 우리가 구축하는 방법을 모르는 시스템에 대해 이야기하고 있다는 것입니다.
그게 또 다른 것이고, 그게 사실 제 믿음입니다. 저는 지금 사람들이 하고 있는 일이 어느 정도까지는 가겠지만, 결국에는 흐지부지될 것이라고 생각합니다.
계속 개선되겠지만, 그것이 '그것'이 되지는 않을 것입니다. 우리가 구축하는 방법을 모르는 '그것'과 많은 것이 신뢰할 수 있는 일반화에 대한 이해에 달려 있습니다.
또 다른 것을 말씀드리겠습니다. 정렬을 어렵게 만드는 원인에 대해 말할 수 있는 것 중 하나는 인간의 가치를 배우는 능력이 취약하다는 것입니다.
그렇다면 그것들을 최적화하는 능력도 취약합니다. 여러분은 실제로 그것들을 최적화하는 것을 배웁니다. 그리고 '이것들이 모두 신뢰할 수 없는 일반화의 예가 아닌가?'라고 말할 수 있지 않나요? 인간은 왜 그렇게 훨씬 더 잘 일반화하는 것처럼 보일까요?
만약 일반화가 훨씬 더 좋았다면 어떨까요? 이 경우에 무슨 일이 일어날까요? 어떤 영향이 있을까요?
하지만 그 질문들은 지금 당장은 여전히 대답할 수 없습니다. AI가 잘 되는 것을 어떻게 생각해야 할까요?
AI가 어떻게 진화할 수 있는지 범위를 정하셨습니다. 우리는 이러한 종류의 지속적인 학습 에이전트를 갖게 될 것입니다.
AI는 매우 강력할 겁니다. 어쩌면 다양한 AI가 많이 존재할 수도 있겠죠. 대륙 크기만한 컴퓨팅 지능이 돌아다니는 것에 대해 어떻게 생각하시나요? 얼마나 위험할까요?
어떻게 하면 덜 위험하게 만들 수 있을까요? 그리고 오정렬된 AI나 나쁜 행위자들이 있을 수 있는 균형을 보호하는 방식으로 어떻게 해야 할까요?
제가 '지각 있는 생명을 보살피는 AI'를 좋아하는 이유 중 하나는, 그것이 좋든 나쁘든 논쟁할 수 있지만, 이러한 극적인 시스템 중 처음 N개가 인류나 그 무엇, 즉 지각 있는 생명을 보살피는 것을 좋아한다면, 당연히 이것 또한 달성되어야 합니다.
이것은 반드시 달성되어야 합니다. 따라서 이러한 시스템 중 처음 N개에 의해 달성된다면, 적어도 꽤 오랫동안은 잘 될 것이라고 봅니다.
그렇다면 장기적으로 어떤 일이 일어날지에 대한 질문이 남습니다. 장기적인 균형을 어떻게 달성할 수 있을까요? 저는 거기에 대한 답도 있다고 생각합니다.
저는 이 답을 좋아하지 않지만, 고려해야 합니다. 장기적으로는 이렇게 말할 수 있습니다. '만약 강력한 AI가 존재하는 세상이 있다면, 단기적으로는 보편적인 고소득을 누릴 수 있을 것이다.
보편적인 고소득을 누리고 우리 모두 잘 살게 될 것이다.' 하지만 불교도들은 뭐라고 말하죠?
"변화만이 유일한 상수이다." 상황은 변합니다. 어떤 정부나 정치 구조 같은 것이 있는데, 이러한 것들은 유통기한이 있기 때문에 변합니다.
어떤 새로운 정부 같은 것이 나타나서 기능을 하다가, 시간이 지나면 기능을 멈춥니다.
이것은 우리가 항상 보는 일입니다. 따라서 장기적인 균형을 위해서는 모든 사람이 자신의 명령을 수행하는 AI를 갖게 되는 것이 하나의 접근 방식일 수 있다고 말할 수 있습니다. 그리고 그것은 좋은 일입니다.
만약 그것이 무기한으로 유지될 수 있다면, 그것은 사실입니다.
하지만 그것의 단점은 AI가 그 사람을 위해 돈을 벌고 정치 영역에서 그들의 필요를 옹호하며, 아마도 '내가 한 일은 이렇고, 상황은 이렇다'라는 짧은 보고서를 작성하면, 그 사람은 '잘했어, 계속 그렇게 해'라고 말합니다. 하지만 그 사람은 더 이상 참여자가 아닙니다.
그렇다면 그것은 불안정한 상황이라고 말할 수 있습니다. 서론에서 말씀드리지만, 저는 이 해결책을 좋아하지 않지만, 해결책은 맞습니다.
해결책은 사람들이 뉴럴링크++ 같은 것으로 부분적으로 AI가 되는 것입니다. 왜냐하면 그렇게 되면 AI가 어떤 것을 이해할 때, 우리도 그것을 이해하게 되기 때문입니다. 이제 이해가 완전히 전달되기 때문입니다.
그래서 이제 AI가 어떤 상황에 처하면, 여러분도 그 상황에 완전히 참여하게 됩니다.
이것이 균형에 대한 해답이라고 생각합니다. 수백만, 혹은 많은 경우 수십억 년 전에 완전히 다른 환경에서 개발된 감정들이 여전히 우리의 행동을 강력하게 이끌고 있다는 사실이 정렬 성공의 한 예인지 궁금합니다.
제가 의미하는 바를 명확히 하자면, 가치 함수라고 불러야 할지, 보상 함수라고 불러야 할지 모르겠지만, 뇌간에는 '더 성공한 사람과 짝짓기하라'는 지시가 있습니다. 피질은 현대 사회에서 성공이 무엇을 의미하는지 이해하는 부분입니다.
그러나 뇌간은 피질을 정렬시켜 '성공을 어떻게 인식하든, 내가 그것이 무엇인지 이해할 만큼 똑똑하지 않더라도, 당신은 여전히 이 지시를 따를 것이다'라고 말할 수 있습니다. 더 일반적인 요점이 있다고 생각합니다.
진화가 어떻게 고차원적인 욕망을 암호화하는지는 정말 불가사의하다고 생각합니다. 진화가 우리에게 냄새가 좋은 음식에 대한 욕망을 부여하는 방법은 이해하기 쉽습니다. 왜냐하면 냄새는 화학 물질이기 때문에 그 화학 물질을 추구하면 되기 때문입니다.
진화가 그런 일을 하는 것을 상상하기는 매우 쉽습니다.
그러나 진화는 우리에게 이러한 모든 사회적 욕망도 부여했습니다. 우리는 사회에 긍정적으로 보이는 것에 대해 정말로 신경 씁니다.
우리는 좋은 평판을 얻는 것에 신경 씁니다. 우리가 가진 이러한 모든 사회적 직관들은 내재되어 있다고 강하게 느낍니다. 진화가 어떻게 그것을 해냈는지 모르겠습니다. 왜냐하면 그것은 뇌에 표현된 고차원적인 개념이기 때문입니다.
예를 들어, 여러분이 어떤 사회적인 것에 대해 신경 쓴다고 가정해 봅시다. 그것은 냄새와 같은 저차원적인 신호가 아닙니다.
센서가 있는 것도 아닙니다. 뇌는 사회적으로 무슨 일이 일어나고 있는지 이해하기 위해 많은 정보를 모아서 처리해야 합니다.
어떻게 된 일인지 진화는 '그것이 당신이 신경 써야 할 것이다'라고 말했습니다. 어떻게 해냈을까요? 그것도 빠르게 해냈습니다.
우리가 신경 쓰는 이러한 모든 정교한 사회적 것들은 꽤 최근에 진화했다고 생각합니다. 진화는 이 고차원적인 욕망을 하드 코딩하는 데 어려움을 겪지 않았습니다.
어떻게 그렇게 되는지에 대한 좋은 가설을 알지 못합니다.
제가 몇 가지 아이디어를 생각해 봤지만 만족스럽지 않았어요. 특히 인상적인 건 평생 동안 학습한 욕망이라면 뇌가 똑똑하기 때문에 이해가 된다는 거죠.
지능적인 욕망을 배울 수 있는 이유가 되는 거죠. 어쩌면 당신의 요점은 아닐 수도 있지만, 욕망이 게놈에 내장되어 있고 게놈은 지능적이지 않다는 점을 이해하는 한 가지 방법이 될 수 있습니다.
하지만 당신은 어떻게든 이 기능을 설명할 수 있습니다. 그 기능을 어떻게 정의하는지도 명확하지 않고, 유전자에 내장할 수도 있습니다.
본질적으로, 아니면 다르게 말할 수도 있겠네요.
게놈이 사용할 수 있는 도구에 대해 생각해 보면, '자, 뇌를 만드는 레시피가 여기 있다'라고 말합니다. '도파민 뉴런을 냄새 센서에 연결하는 레시피가 여기 있다'라고 말할 수도 있습니다. 그리고 그 냄새가 특정한 좋은 냄새라면, 그걸 먹고 싶어하겠죠.
게놈이 그렇게 할 수 있을 거라고 상상할 수 있습니다.
저는 상상하기가 더 어렵다고 주장하는 겁니다. 게놈이 '뇌 전체, 뇌의 큰 덩어리가 하는 복잡한 계산에 신경 써야 한다'라고 말하는 것을 상상하기는 더 어렵습니다. 그게 제가 주장하는 전부입니다.
어떻게 그렇게 할 수 있는지에 대한 추측을 말씀드릴 수 있습니다.
추측을 하나 제시해 보고, 왜 그 추측이 아마도 틀렸을지 설명해 드리겠습니다. 뇌에는 여러 뇌 영역이 있습니다. 우리에겐 피질이 있죠. 그 피질에는 모든 뇌 영역이 있습니다.
피질은 균일하지만, 피질의 뇌 영역과 뉴런은 대부분 이웃과만 소통합니다. 그게 뇌 영역이 생기는 이유를 설명해 줍니다.
왜냐하면 어떤 종류의 음성 처리를 하고 싶다면, 음성 처리를 하는 모든 뉴런이 서로 소통해야 하기 때문입니다. 그리고 뉴런은 대부분 근처 이웃과만 소통할 수 있기 때문에, 영역이 있어야 합니다.
모든 영역은 사람마다 거의 같은 위치에 있습니다.
그래서 어쩌면 진화는 뇌의 특정 위치를 문자 그대로 하드 코딩했을지도 모릅니다. 그래서 '아, 뇌의 GPS 좌표가 이러저러할 때, 그게 발화되면 신경 써야 한다'라고 말하는 거죠. 어쩌면 진화가 그런 식으로 했을지도 모릅니다. 왜냐하면 그게 진화의 툴킷 안에 있을 테니까요.
네, 시각 장애인으로 태어난 사람들의 경우 피질의 해당 영역이 다른 감각에 의해 채택되는 경우도 있습니다.
저는 잘 모르겠지만, 시각 신호를 필요로 하는 욕망이나 보상 기능이 피질의 다른 영역을 공동으로 사용하는 사람들에게 더 이상 작동하지 않는다면 놀랄 것 같습니다.
예를 들어, 시력이 없다면 주변 사람들이 나를 좋아했으면 좋겠다는 느낌을 여전히 받을 수 있을까요? 보통 시각적인 신호도 있을 텐데요.
전적으로 동의합니다. 이 이론에 대한 훨씬 더 강력한 반론이 있다고 생각합니다.
어린 시절에 뇌의 절반을 제거한 사람들이 있는데, 그들은 여전히 모든 뇌 영역을 가지고 있습니다. 하지만 그들은 모두 어떻게든 하나의 반구로 이동하는데, 이는 뇌 영역의 위치가 고정되어 있지 않다는 것을 시사하며, 따라서 그 이론은 사실이 아닙니다.
사실이었다면 멋있었겠지만, 그렇지 않습니다.
그래서 저는 그것이 미스터리라고 생각합니다.
하지만 흥미로운 미스터리입니다. 사실은 어떻게든 진화가 우리에게 사회적인 것에 대해 매우, 매우 확실하게 관심을 갖도록 해줬다는 것입니다.
온갖 이상한 정신 질환과 결핍, 정서적 문제를 가진 사람들조차도 이것에 관심을 갖는 경향이 있습니다.
SSI는 무엇을 다르게 할 계획인가요? 아마도 당신의 계획은 이 시기가 왔을 때 선두 기업 중 하나가 되는 것이겠죠. 아마도 당신은 '다른 회사들이 안전하게 접근하는 방식과는 다른 방식으로 접근할 수 있는 방법이 있다고 생각한다'라고 생각해서 SSI를 시작했을 겁니다. 그 차이점은 무엇인가요?
제가 설명하는 방식은 제가 생각하기에 유망한 아이디어가 있고, 그것들이 정말로 유망한지 아닌지 조사하고 싶다는 것입니다.
정말 간단합니다. 시도입니다. 만약 그 아이디어가 옳다는 것이 밝혀진다면, 즉 우리가 일반화에 대해 논의했던 아이디어가 옳다면, 우리는 가치 있는 것을 갖게 될 것이라고 생각합니다.
그것들이 옳다는 것이 밝혀질까요? 우리는 연구를 하고 있습니다.
우리는 명확히 '연구의 시대' 회사입니다. 우리는 진전을 이루고 있습니다. 우리는 실제로 지난 1년 동안 꽤 좋은 진전을 이루었지만, 더 많은 진전, 더 많은 연구를 계속해야 합니다.
저는 그렇게 봅니다. 저는 그것을 목소리를 내고 참여하려는 시도로 봅니다.
당신의 공동 창업자이자 이전 CEO가 최근 Meta로 떠났고, 사람들은 '만약 많은 획기적인 발전이 있었다면, 그것은 일어나기 어려웠을 것 같다'라고 질문했습니다. 어떻게 답변하시겠습니까?
이를 위해 잊혀졌을 수도 있는 몇 가지 사실을 간단히 상기시켜 드리겠습니다.
이러한 사실들이 상황을 설명하는 맥락을 제공한다고 생각합니다. 당시 상황은 우리가 320억 달러의 가치로 자금 조달을 하고 있었는데, 메타에서 우리를 인수하겠다는 제안이 들어왔고, 저는 거절했습니다. 하지만 제 전 공동 창업자는 어떤 의미에서는 동의했습니다.
결과적으로 그는 단기 유동성을 누릴 수 있었고, SSI에서 메타에 합류한 유일한 사람이었습니다.
SSI의 계획은 초인적인 지능을 갖게 되는 인류 역사상 매우 중요한 시기에 최전선에 있는 회사가 되는 것 같습니다.
초인적인 지능을 잘 활용하는 방법에 대한 아이디어가 있을 텐데요.
다른 회사들도 자체적인 아이디어를 시도할 것입니다. 초지능을 잘 활용하기 위한 SSI의 접근 방식의 차별점은 무엇인가요?
SSI의 가장 큰 차별점은 기술적 접근 방식입니다. 우리는 가치 있는 기술적 접근 방식을 가지고 있으며 이를 추구하고 있습니다.
결국 전략이 수렴될 것이라고 생각합니다. AI가 더욱 강력해짐에 따라, 어느 시점에서는 전략이 무엇이어야 하는지 모든 사람에게 더 명확해질 것이라고 생각합니다.
서로 대화할 방법을 찾아야 하고, 최초의 실제 초지능 AI가 정렬되어 있고, 어떻게든 지각 있는 생명체를 배려하고, 사람을 배려하고, 민주적이고, 이들의 조합 중 하나여야 합니다.
이것이 모든 사람이 추구해야 할 조건이라고 생각합니다. SSI는 이를 위해 노력하고 있습니다. 이번에는 이미 그렇듯이 다른 모든 회사들도 같은 것을 향해 노력하고 있다는 것을 깨닫게 될 것이라고 생각합니다.
두고 봅시다. AI가 더욱 강력해짐에 따라 세상이 진정으로 바뀔 것이라고 생각합니다.
상황이 정말 많이 달라지고 사람들이 정말 다르게 행동할 것이라고 생각합니다. 예측에 대해 말하자면, 인간만큼 잘 배우고 결과적으로 초인적이 될 수 있는 당신이 설명하는 이 시스템에 대한 예측은 무엇입니까?
5년에서 20년 정도라고 생각합니다. 5년에서 20년이요?
음. 세상이 어떻게 흘러갈지 당신의 관점을 알고 싶습니다. 현재 접근 방식을 계속하는 다른 회사들이 몇 년 더 있다가 정체될 것 같습니다. 여기서 '정체'란 매출이 수천억 달러를 넘지 못한다는 뜻인가요?
정체된다는 것이 무엇을 의미한다고 생각하시나요? 제 생각에는 정체되는 모습은 모든 회사에서 매우 비슷하게 보일 것입니다.
이런 모습일 수도 있습니다. 정체되더라도 이 회사들이 엄청난 수익을 올릴 수 있다고 생각하기 때문에 확신할 수는 없습니다.
서로 차별화하기 위해 열심히 노력해야 하므로 이익은 아닐 수도 있지만, 매출은 확실히 그럴 것입니다. 하지만 당신의 모델에는 올바른 솔루션이 나오면 모든 회사가 수렴될 것이라는 의미가 담겨 있습니다.
왜 그렇게 생각하는지 궁금합니다. 저는 그들의 얼라인먼트 전략에 대한 수렴에 대해 더 이야기하고 있었습니다.
기술적 접근 방식에 대한 궁극적인 수렴도 일어날 가능성이 높다고 생각하지만, 저는 얼라인먼트 전략에 대한 수렴을 암시하고 있었습니다.
정확히 무엇을 해야 할까요? 미래가 어떻게 펼쳐질지 더 잘 이해하고 싶습니다.
현재 여러 회사가 있고, 당신은 그들의 접근 방식이 계속해서 수익을 창출하지만 인간과 같은 학습자에는 도달하지 못할 것이라고 예상합니다. 그래서 지금은 여러 회사가 분기되어 있습니다.
당신, Thinking Machines, 그리고 다른 많은 연구소가 있습니다. 그중 하나가 올바른 접근 방식을 알아낼 수도 있습니다.
하지만 그들의 제품 출시로 인해 다른 사람들이 이 일을 어떻게 해야 하는지 명확해집니다. 어떻게 해야 하는지는 명확하지 않겠지만, 뭔가 다른 것이 가능하다는 것이 명확해질 것이고, 그것이 정보입니다.
사람들은 그 작동 방식을 알아내려고 노력할 것입니다. 하지만 여기서 다루지 않은, 논의되지 않은 것 중 하나는 AI의 능력이 향상될 때마다 어떤 종류의 변화가 있을 것이라는 점입니다. 하지만 정확히 어떤 변화인지는 모르겠습니다.
중요할 것이라고 생각하지만 정확히 무엇인지는 말할 수 없습니다.
기본적으로 해당 모델을 가진 회사는 모델이 세상에서 쌓아가는 기술과 지식을 가지고 있기 때문에 이러한 모든 이득을 얻을 것으로 예상할 수 있습니다.
그렇게 되면 그 이점이 널리 분산되지 않고, 지속적인 학습 루프를 먼저 시작하는 모델 회사에만 귀착되지 않을 것이라고 생각하는 이유는 무엇인가요?
제 생각에는 앞으로 이런 일이 벌어질 것 같습니다. 첫째, 과거 AI의 상황이 어떻게 진행되었는지 살펴보겠습니다.
한 회사가 발전을 이루면 다른 회사가 서둘러 비슷한 것을 만들어 내고, 어느 정도 시간이 지나면 시장에서 경쟁을 시작하고 가격을 낮추기 시작했습니다.
그래서 시장 관점에서도 비슷한 일이 일어날 것이라고 생각합니다. 그런데 우리는 좋은 세상을 이야기하고 있습니다.
좋은 세상이란 무엇일까요? 강력한 인간과 유사한 학습기가 있는 곳입니다. 그런데 우리가 초지능 AI의 사양에 대해 논의하지 않은 또 다른 고려할 가치가 있는 점이 있습니다.
좁게 만드는 것입니다. 유용하면서도 좁을 수 있습니다. 좁은 초지능 AI를 많이 가질 수 있습니다.
하지만 그런 AI가 많고, 어떤 회사가 그것으로 많은 이익을 얻고 있다고 가정해 봅시다. 그러면 다른 회사가 들어와 경쟁을 시작합니다.
경쟁 방식은 전문화를 통하는 것입니다. 경쟁은 전문화를 좋아합니다. 시장에서도 볼 수 있고, 진화에서도 볼 수 있습니다.
다양한 틈새 시장이 생기고, 다양한 틈새 시장을 차지하는 다양한 회사가 생길 것입니다.
이 세상에서 우리는 한 AI 회사가 매우 복잡한 경제 활동의 특정 분야에서 훨씬 더 뛰어나고, 다른 회사는 다른 분야에서 더 뛰어나다고 말할 수 있습니다.
그리고 세 번째 회사는 소송에 능숙합니다. 이것은 인간과 유사한 학습이 의미하는 바와 모순되지 않습니까? 학습할 수 있다는 것인데요...
할 수 있지만, 학습이 축적됩니다. 큰 투자를 했습니다. 이 분야에서 정말, 정말 훌륭해지기 위해 많은 연산을 사용했습니다.
다른 사람은 다른 분야에서 정말 잘하기 위해 엄청난 양의 연산과 엄청난 양의 경험을 투자했습니다. 거기에 도달하기 위해 많은 인간 학습을 적용하지만, 이제 다른 사람이 '봐, 나는 당신이 배운 것을 배우고 싶지 않아'라고 말할 수 있는 높은 지점에 도달했습니다. 제 생각에는 여러 회사가 동시에 인간과 유사한 지속적인 학습 에이전트로 시작하여 다른 분기에서 다른 트리 검색을 시작해야 할 것입니다.
하지만 어떤 회사가 그 에이전트를 먼저 얻거나, 학습자를 먼저 얻게 되면, 마치 이런 생각이 들게 됩니다. 경제의 모든 직업에 대해 각각의 인스턴스가 학습하는 것이 회사에 적합해 보입니다.
그것은 타당한 주장이네요. 제 강한 직감은 그렇게 흘러가지 않을 거라는 겁니다.
그 주장은 그렇게 될 것이라고 말하지만, 제 강한 직감은 그렇게 되지 않을 거라는 겁니다.
이론상으로는 이론과 실제 사이에 차이가 없습니다. 하지만 실제로는 차이가 있죠. 그게 바로 그런 것 중 하나가 될 거라고 생각합니다.
많은 사람들의 재귀적 자기 개선 모델은 문자 그대로, 명시적으로 서버에 수백만 명의 일리야가 있어서 서로 다른 아이디어를 내고, 이것이 매우 빠르게 초지능의 출현으로 이어질 것이라고 말합니다.
당신이 하고 있는 일이 얼마나 병렬화될 수 있는지에 대한 직감이 있나요? 일리야를 복제해서 얻는 이득은 무엇인가요?
모르겠어요. 저는 확실히 수익 감소가 있을 거라고 생각합니다. 왜냐하면 같은 생각을 하는 사람보다는 다른 생각을 하는 사람들이 필요하니까요.
만약 저의 문자 그대로의 복사본이 있다면, 얼마나 더 점진적인 가치를 얻을 수 있을지 확신할 수 없네요.
다른 생각을 하는 사람들이 당신이 원하는 것입니다. 왜 서로 다른 회사에서 출시한 모델들을 보면, 잠재적으로 겹치지 않는 데이터 세트로 훈련되었음에도 불구하고, LLM들이 서로 얼마나 유사한지 놀라울 정도일까요?
아마 데이터 세트가 보이는 것만큼 겹치지 않을 수도 있습니다. 하지만 미래의 AI보다 개별 인간이 덜 생산적일지라도, 인간 팀이 AI 팀보다 더 다양한 면이 있을 수도 있다는 점이 중요할 수도 있습니다.
AI 간에 의미 있는 다양성을 어떻게 이끌어낼 수 있을까요?
온도를 높이는 것은 그저 횡설수설만 초래할 뿐이라고 생각합니다. 서로 다른 과학자들이 서로 다른 편견이나 아이디어를 갖는 것과 같은 것이 필요합니다.
AI 에이전트 간에 그런 종류의 다양성을 어떻게 얻을 수 있을까요? 다양성이 없었던 이유는 프리 트레이닝 때문이라고 생각합니다.
모든 사전 훈련된 모델은 거의 동일한 데이터로 사전 훈련하기 때문에 거의 같습니다. 이제 RL과 사후 훈련은 서로 다른 사람들이 서로 다른 RL 훈련을 생각해내기 때문에 차별화가 시작되는 곳입니다.
과거에 데이터를 얻거나 동등한 지능을 가진 에이전트를 다른 에이전트와 매칭하여 학습을 시작하는 방법으로 자체 플레이에 대해 넌지시 언급하신 것을 들었습니다.
왜 LLM으로 이런 종류의 작업을 하는 공개 제안이 없는지 어떻게 생각해야 할까요?
두 가지 말씀드릴 수 있습니다. 제가 자체 플레이를 흥미롭게 생각했던 이유는 데이터 없이 컴퓨팅만 사용하여 모델을 만들 수 있는 방법을 제공했기 때문입니다.
데이터가 궁극적인 병목 현상이라고 생각한다면 컴퓨팅만 사용하는 것이 매우 흥미롭습니다. 그래서 흥미로운 것입니다. 문제는 자체 플레이는 적어도 과거에 행해졌던 방식대로 에이전트가 서로 경쟁할 때 특정 기술 세트를 개발하는 데만 유용하다는 것입니다.
너무 좁습니다. 협상, 갈등, 특정 사회성 기술, 전략 수립 등과 같은 종류의 기술에만 유용합니다.
이러한 기술에 관심이 있다면 자체 플레이가 유용할 것입니다.
사실 자체 플레이는 다른 형태로 자리를 잡았다고 생각합니다. 토론, 증명자-검증자와 같은 것들은 당신의 작업에서 실수를 찾도록 장려되는 LLM-as-a-Judge와 같은 것이 있습니다.
이것이 정확히 자체 플레이는 아니지만 사람들이 하고 있는 관련 적대적 설정이라고 말할 수 있습니다.
정말로 자체 플레이는 에이전트 간의 더 일반적인 경쟁의 특별한 경우입니다. 경쟁에 대한 자연스러운 반응은 달라지려고 노력하는 것입니다.
그래서 여러 에이전트를 함께 놓고 "당신은 모두 어떤 문제에 대해 작업해야 하고 당신은 에이전트이며 다른 모든 사람이 무엇을 하고 있는지 검사하고 있습니다."라고 말하면 그들은 "글쎄요, 그들이 이미 이 접근 방식을 취하고 있다면 제가 그것을 추구해야 할지는 분명하지 않습니다."라고 말할 것입니다.
저는 차별화된 것을 추구해야 합니다." 그래서 저는 이런 종류의 것이 접근 방식의 다양성에 대한 인센티브를 만들 수도 있다고 생각합니다. 마지막 질문: 연구 취향이란 무엇입니까?
당신은 분명히 AI 연구를 하는 데 있어 최고의 취향을 가진 사람으로 여겨집니다. 당신은 AlexNet에서 GPT-3에 이르기까지 딥 러닝 역사상 가장 큰 일들의 공동 저자였습니다.
그것은 무엇이며, 이러한 아이디어를 어떻게 생각해내는지 어떻게 특징짓습니까?
이 점에 대해 제 생각을 말씀드릴 수 있습니다. 사람마다 다르게 하는 것 같아요. 개인적으로 저를 이끄는 한 가지는 AI가 어떻게 되어야 하는지에 대한 미학인데, 사람들이 어떤지 생각하되 올바르게 생각하는 것입니다.
사람들이 어떤지 잘못 생각하기는 매우 쉽지만, 사람들에 대해 올바르게 생각한다는 것은 무엇을 의미할까요? 몇 가지 예를 들어보겠습니다.
인공 뉴런이라는 아이디어는 뇌에서 직접 영감을 얻은 것이며, 훌륭한 아이디어입니다.
왜냐하면 뇌에는 여러 기관이 있고, 주름도 있지만, 주름은 중요하지 않을 것입니다. 왜 우리는 뉴런이 중요하다고 생각할까요?
왜냐하면 뉴런이 많이 있기 때문입니다. 왠지 맞는 것 같고, 그래서 뉴런을 원하게 됩니다. 뉴런 간의 연결을 변경하는 국소 학습 규칙을 원합니다.
뇌가 그렇게 할 것 같다는 느낌이 듭니다. 분산 표현이라는 아이디어, 뇌가 경험에 반응한다는 아이디어, 따라서 우리의 신경망은 경험으로부터 배워야 합니다.
뇌는 경험으로부터 배우고, 신경망은 경험으로부터 배워야 합니다. 여러분은 스스로에게 묻습니다. 무엇이 근본적인 것이고, 무엇이 근본적이지 않은가?
어떻게 되어야 하는가. 저는 여러 각도에서 생각하고 거의 아름다움, 아름다움과 단순함을 추구하면서 꽤 많은 지침을 받아왔다고 생각합니다.
추함은 용납할 수 없습니다. 아름다움, 단순함, 우아함, 뇌로부터의 올바른 영감이 있어야 합니다.
이 모든 것이 동시에 존재해야 합니다. 그것들이 더 많이 존재할수록, 하향식 믿음에 대해 더 확신할 수 있습니다.
하향식 믿음은 실험이 여러분과 모순될 때 여러분을 지탱해주는 것입니다. 왜냐하면 데이터를 항상 신뢰하면, 때로는 올바른 일을 하고 있지만 버그가 있을 수 있기 때문입니다.
하지만 버그가 있다는 것을 모릅니다. 버그가 있다는 것을 어떻게 알 수 있을까요?
계속 디버깅해야 할지, 아니면 잘못된 방향이라고 결론 내려야 할지 어떻게 알 수 있을까요? 그것은 하향식입니다.
여러분은 이렇게 말할 수 있습니다. 상황은 이렇게 되어야 합니다. 이런 종류의 것은 작동해야 하므로, 계속 진행해야 합니다. 그것이 하향식이며, 다면적인 아름다움과 뇌에 의한 영감을 기반으로 합니다.
좋습니다. 여기서 마무리하겠습니다.
정말 감사합니다. 일리야, 정말 감사합니다. 좋습니다. 감사합니다. 정말 좋았습니다.
네, 즐거웠습니다. 저도요.