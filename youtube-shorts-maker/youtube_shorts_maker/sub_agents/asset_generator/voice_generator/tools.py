from google.genai import types
from openai import OpenAI
from google.adk.tools.tool_context import ToolContext
from typing import List, Dict, Any
import traceback  # ğŸ‘ˆ ì˜¤ë¥˜ ì¶”ì ì„ ìœ„í•´ ì¶”ê°€

client = OpenAI()


async def generate_narrations(
    tool_context: ToolContext, voice: str, voice_instructions: List[Dict[str, Any]]
):
    """
    Generate narration audio for each scene using OpenAI TTS API
    """

    print("\n--- ğŸ™ï¸ Voice Generator ì‹œì‘ ---")
    existing_artifacts = await tool_context.list_artifacts()
    generated_narrations = []

    if not voice_instructions:
        print("[WARN] 'voice_instructions'ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. Voice Generatorë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        # ğŸ‘ˆ [ìˆ˜ì •] ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¼ë„ ì •ìƒ ì¢…ë£Œë˜ë„ë¡ ìˆ˜ì •
        return {
            "success": True,
            "narrations": [],
            "total_narrations": 0,
        }

    for instruction in voice_instructions:
        try:
            text_input = instruction.get("input")
            scene_id = instruction.get("scene_id")
            filename = f"scene_{scene_id}_narration.mp3"
            
            # ğŸ‘ˆ [ìˆ˜ì •] instructionsê°€ Noneì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„
            instructions_raw = instruction.get("instructions", "")
            instructions_log = instructions_raw[:50] if instructions_raw else ""


            if filename in existing_artifacts:
                print(f"[INFO] ì˜¤ë””ì˜¤ íŒŒì¼ {filename}ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤.")
                generated_narrations.append(
                    {
                        "scene_id": scene_id,
                        "filename": filename,
                        "input": text_input,
                        "instructions": instructions_log,
                    }
                )
                continue

            # --- 1. OpenAI TTS API í˜¸ì¶œ ---
            print(f"[INFO] ì”¬ {scene_id}ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ({filename}) ìƒì„± ì¤‘...")
            with client.audio.speech.with_streaming_response.create(
                model="gpt-4o-mini-tts",
                voice=voice,
                input=text_input
                # 'instructions' íŒŒë¼ë¯¸í„°ëŠ” APIì— ì—†ìœ¼ë¯€ë¡œ ì œì™¸
            ) as response:
                audio_data = response.read()

            # --- 2. ì•„í‹°íŒ©íŠ¸ ìƒì„± ë° ì €ì¥ ---
            artifact = types.Part(
                inline_data=types.Blob(mime_type="audio/mpeg", data=audio_data)
            )

            await tool_context.save_artifact(filename=filename, artifact=artifact)
            print(f"[SUCCESS] ì”¬ {scene_id}ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ {filename} ì €ì¥ ì™„ë£Œ.")

            generated_narrations.append(
                {
                    "scene_id": scene_id,
                    "filename": filename,
                    "input": text_input,
                    "instructions": instructions_log,
                }
            )
        
        except Exception as e:
            # ğŸ‘ˆ [ìˆ˜ì •] ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë©ˆì¶”ì§€ ì•Šê³  ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë‹¤ìŒ ì”¬ìœ¼ë¡œ ì´ë™
            print(f"âŒ [ERROR] ì”¬ {scene_id} ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            print(traceback.format_exc()) # ğŸ‘ˆ ë” ìì„¸í•œ ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥
            continue # ë‹¤ìŒ ë£¨í”„ë¡œ ë„˜ì–´ê°

    # --- 3. (í™•ì¸) 'return' ë¬¸ì´ for ë£¨í”„ ë°–ì— ìˆìŒ ---
    print(f"--- ğŸ™ï¸ Voice Generator ì¢…ë£Œ: ì´ {len(generated_narrations)}ê°œì˜ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ ---")
    return {
        "success": True,
        "narrations": generated_narrations,
        "total_narrations": len(generated_narrations),
    }